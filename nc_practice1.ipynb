{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考（照抄）netCDF4官方文档的笔记<br>\n",
    "                        \n",
    "---\n",
    "\n",
    "[官方文档网址](https://unidata.github.io/netcdf4-python/netCDF4/index.html#section1)\n",
    "\n",
    "---\n",
    "                        \n",
    "大部分是直接机翻，能用就行了<br>\n",
    "注意会在ipynb同目录下建立几个nc文件用于测试,请放在合适的目录下使用\n",
    "有不恰当机翻的地方尽量用括号给出原文，出现~~这种带有删除线的文字~~大都是可看可不看翻译者用于自省的部分                        \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6> 介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "netcdf4-python是netCDF C库的Python接口。<br>\n",
    "[netcdf4](http://www.unidata.ucar.edu/software/netcdf/) version 4具有早期版本的库中未建立的许多功能，并在[HDF5](http://www.hdfgroup.org/HDF5)之上实现 。此模块可以读取和写入新的netCDF 4和旧的netCDF 3格式的文件，并且可以创建HDF5客户端可读的文件。该API是根据[Scientific.IO.NetCDF](http://dirac.cnrs-orleans.fr/ScientificPython/)编写的 ，对该模块的用户应该方便上手。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "netCDF 4实现了很多新功能，例如多个无限制的尺寸，group，和zlib数据压缩。所有新的数字数据类型（例如64位和无符号整数类型）都已实现。支持复合（struct），可变长度（vlen）和枚举（enum）数据类型，但不透明数据类型不受支持。不支持复合类型，vlen和枚举数据类型的混合数据（例如包含枚举的复合类型或包含复合类型的vlen）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6>下载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 来自[github](http://github.com/Unidata/netcdf4-python)仓库的最新前沿代码。\n",
    "* [最新版本](https://pypi.python.org/pypi/netCDF4) （源代码和二进制安装程序）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~废话~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 快速开始\n",
    "* 克隆github仓库(`git clone https://github.com/Unidata/netcdf4-python.git`), 或从[PyPI](https://pypi.python.org/pypi/netCDF4)中获取源tarball. [PyPI](https://pypi.python.org/pypi/netCDF4)还提供了指向 Windows 和 OS X的二进制预编译包的链接。\n",
    "* 确保[numpy](http://www.numpy.org/) and [Cython](http://cython.org/)都已经安装，并且[Python](https://www.python.org) 2.7或更高版本已经可用.\n",
    "\n",
    "* 确保[HDF5](http://www.h5py.org/) 和 netcdf-4都已经安装, 并且`nc-config`应用程序已经在你的UNIX路径中。 \n",
    "\n",
    "* 运行`python setup.py build`, 接着是`python setup.py install` (如果必要的话请使用`sudo`)。\n",
    "\n",
    "* 运行所有测试程序，执行`cd test && python run_all.py`.~这段直接翻译git上的readme所以先保留~\n",
    "\n",
    "## 文档\n",
    "在线文档中更多内容[docs](http://unidata.github.io/netcdf4-python).\n",
    "\n",
    "## 用法\n",
    "* Sample [iPython](http://ipython.org/) notebook在示例目录下可用，从python中[reading](http://nbviewer.ipython.org/github/Unidata/netcdf4-python/blob/master/examples/reading_netCDF.ipynb) and [writing](http://nbviewer.ipython.org/github/Unidata/netcdf4-python/blob/master/examples/writing_netCDF.ipynb) netCDF数据（其实就是简化版的教程，~**短小但非常实用！**~）\n",
    "\n",
    "## 使用netcdf4-python的其他有趣且有用的项目\n",
    "- [xarray](https://xarray.pydata.org/en/stable/): 可以对netcdf变量进行操作的，核心为[pandas](https://pandas.pydata.org)数据结构的n维变体。\n",
    "- [Iris](https://scitools.org.uk/iris/docs/latest/): 用于创建数据抽象层的数据模型，该抽象层将分析和可视化代码与数据格式细节隔离开来。使用netcdf4-python访问netcdf数据（也可以处理GRIB）。\n",
    "- [Dask](https://dask.org/): 具有lazy evaluation的虚拟大型数组（来自netcdf变量）。\n",
    "- [cf-python](https://cfpython.bitbucket.io/): 实现[CF](http://cfconventions.org)数据模型，以读取、写入和处理数据和元数据。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6> 教程部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font face=\"黑体\" size=5>创建/打开/关闭netCDF文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset函数调用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要从python创建netCDF文件，只需调用Dataset 构造函数。这也是用于打开现有netCDF文件的方法。如果文件已打开以进行写访问（mode='w', 'r+'或'a'），则可以写入任何类型的数据，包括新的维，组，变量和属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETCDF4\n"
     ]
    }
   ],
   "source": [
    ">>> from netCDF4 import Dataset\n",
    ">>> rootgrp = Dataset(\"test.nc\", \"w\", format=\"NETCDF4\") # 在同一目录下创建nc4的练习文件\n",
    ">>> print(rootgrp.data_model) # 输出文件类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建新文件时，可以使用构造函数中的format 关键字指定格式Dataset。默认格式为 NETCDF4。要查看给定文件的格式，可以检查 data_model属性。关闭netCDF文件是通过 实例的close方法完成的Dataset。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NETCDF4'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootgrp.data_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~注意如果不将nc文件关闭，在重新运行同一段内容时会出现访问的权限错误！~~\n",
    "下面是示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: b'test.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-29d674552d37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrootgrp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test.nc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"NETCDF4\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 再次创建，报错，需要使用下面的关闭命令\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: b'test.nc'"
     ]
    }
   ],
   "source": [
    ">>> rootgrp = Dataset(\"test.nc\", \"w\", format=\"NETCDF4\") # 再次创建，报错，需要使用下面的关闭命令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> rootgrp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文件类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文件类型：<br>\n",
    "netCDF文件有五种（NETCDF3_CLASSIC, NETCDF3_64BIT_OFFSET, NETCDF3_64BIT_DATA, NETCDF4_CLASSIC和NETCDF4）。<br> NETCDF3_CLASSIC是原始的netcdf二进制格式，并且文件大小限制为小于2 Gb。<br>\n",
    "NETCDF3_64BIT_OFFSET是在库的3.6.0版中引入的，并扩展了原始二进制格式以允许文件大小大于2 Gb。<br> \n",
    "NETCDF3_64BIT_DATA是一种新格式，需要C库的4.4.0版-它扩展了NETCDF3_64BIT_OFFSET二进制格式以允许无符号/ 64位整数数据类型和64位尺寸大小。 <br>\n",
    "NETCDF3_64BIT是的别名NETCDF3_64BIT_OFFSET。<br> \n",
    "NETCDF4_CLASSIC文件使用版本4磁盘格式（HDF5），但省略了版本3 API中未提供的功能。只有将它们与netCDF 4库重新链接后，它们才能被netCDF 3客户端读取。<br>\n",
    "HDF5客户端也可以读取它们。NETCDF4文件使用版本4磁盘格式（HDF5），并使用版本4 API的新功能。该 netCDF4模块可以以任何这些格式读取和写入文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font face=\"黑体\" size=5>在netCDF文件中进行分组。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## group的说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "netCDF版本4新增了对按层次结构组织数据的支持，这些层次结构类似于文件系统中的目录。组用作变量，维和属性以及其他组的容器。<br>\n",
    "Dataset创建一个特殊的组，称为“根组”，它类似于UNIX文件系统中的根目录。<br>\n",
    "要创建Group实例，请使用createGroup方法。有一个参数:即新组名称的python字符串。<br>\n",
    "可以使用实例的字典属性通过名称访问根组中包含的新实例。<br>\n",
    "注意：仅格式化文件支持组，如果尝试在netCDF 3文件中创建组，则会收到错误消息。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~remains:所有怎么具体访问某个组的变量？(非常重要，这影响了读取出来的数据是netcdf4类型或是别的类型（例如np_array）)~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'forecasts': <class 'netCDF4._netCDF4.Group'>\n",
      "group /forecasts:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: , 'analyses': <class 'netCDF4._netCDF4.Group'>\n",
      "group /analyses:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: }\n"
     ]
    }
   ],
   "source": [
    ">>> rootgrp = Dataset(\"test.nc\", \"a\")\n",
    ">>> fcstgrp = rootgrp.createGroup(\"forecasts\")\n",
    ">>> analgrp = rootgrp.createGroup(\"analyses\")\n",
    ">>> print(rootgrp.groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "组可以存放于的组中Dataset，就像目录存放于unix文件系统中的目录中一样<br>\n",
    "每个Group实例都有一个groups属性字典，其中包含该组中包含的所有组实例。<br>\n",
    "每个Group实例还具有一个path属性，该 属性包含该组的模拟的UNIX目录路径。为了简化嵌套组的创建，您可以使用类unix的路径作为的参数createGroup。<br>\n",
    "如果路径中的任何中间元素都不存在，则会像使用unix命令一样创建它们'mkdir -p'。<br>\n",
    "如果您尝试创建一个已经存在的组，则不会出现任何错误，并且将返回现有的组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model1': <class 'netCDF4._netCDF4.Group'>\n",
       " group /forecasts/model1:\n",
       "     dimensions(sizes): \n",
       "     variables(dimensions): \n",
       "     groups: ,\n",
       " 'model2': <class 'netCDF4._netCDF4.Group'>\n",
       " group /forecasts/model2:\n",
       "     dimensions(sizes): \n",
       "     variables(dimensions): \n",
       "     groups: }"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> fcstgrp1 = rootgrp.createGroup(\"/forecasts/model1\")\n",
    ">>> fcstgrp2 = rootgrp.createGroup(\"/forecasts/model2\")\n",
    "fcstgrp.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Group'>\n",
       "group /forecasts/model1:\n",
       "    dimensions(sizes): \n",
       "    variables(dimensions): \n",
       "    groups: "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcstgrp.groups['model1'] # 访问fcstgrp中的groups中的model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面一个示例，显示了如何导航中的所有组 Dataset。该函数walktree是一个Python生成器，用于遍历目录树。请注意，打印Dataset或Group 对象会产生有关其内容的摘要信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> def walktree(top):\n",
    "...     values = top.groups.values()\n",
    "...     yield values\n",
    "...     for value in top.groups.values():\n",
    "...         for children in walktree(value):\n",
    "...             yield children #child下的字典的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Group'>\n",
      "group /forecasts:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: model1, model2\n",
      "<class 'netCDF4._netCDF4.Group'>\n",
      "group /analyses:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: \n",
      "<class 'netCDF4._netCDF4.Group'>\n",
      "group /forecasts/model1:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: \n",
      "<class 'netCDF4._netCDF4.Group'>\n",
      "group /forecasts/model2:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    ">>> for children in walktree(rootgrp):\n",
    "#         print(children)\n",
    "...     for child in children:\n",
    "...         print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Group'>\n",
       "group /forecasts/model1:\n",
       "    dimensions(sizes): \n",
       "    variables(dimensions): \n",
       "    groups: "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#yield的返回值和python的 迭代器 相关，remains；\n",
    "#下面是一个手动的生成的\n",
    "rootgrp.groups['forecasts'].groups['model1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=5>netCDF文件中的维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "netCDF根据维度定义了所有变量的大小，因此在创建任何变量之前，必须首先创建它们使用的维度。\n",
    "（除非是实践中不经常使用的一种特殊情况，那就是标量变量，它没有尺寸。）\n",
    "使用Dataset或者groups中的createDimension方法创建维。参数中：Python字符串用于设置尺寸名称，而整数值用于设置尺寸。要创建无限制的尺寸（可以附加到尺寸的尺寸），请将大小值设置为或0。\n",
    "在此示例中，和 尺寸均不受限制。netCDF 4的一项新功能是具有一个以上的无限维，在netCDF 3文件中，可能只有一个，并且它必须是变量的第一个（最左侧）维。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF4 data model, file format HDF5):\n",
       "    dimensions(sizes): \n",
       "    variables(dimensions): \n",
       "    groups: forecasts, analyses"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootgrp #维度定义前"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> level = rootgrp.createDimension(\"level\", None)\n",
    ">>> time = rootgrp.createDimension(\"time\", None)\n",
    ">>> lat = rootgrp.createDimension(\"lat\", 73)\n",
    ">>> lon = rootgrp.createDimension(\"lon\", 144)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len使用Dimension实例调用python 函数将返回该维度的当前大小。实例的isunlimited方法Dimension可用于确定尺寸是无限的还是可追加的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    ">>> print(len(lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    ">>> print(lon.isunlimited())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    ">>> print(time.isunlimited())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有Dimension实例都存储在python字典中，下面用一个循环进行输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'level', size = 0\n",
      "<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 73\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 144\n"
     ]
    }
   ],
   "source": [
    "# rootgrp.dimensions.values() # 或者一个一个输出\n",
    ">>> for dimobj in rootgrp.dimensions.values():\n",
    "...     print(dimobj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font size=5> netCDF文件中的变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "netCDF变量的操作非常类似于numpy模块提供的python多维数组对象。但是与numpy数组不同，netCDF4变量可以沿一个或多个“无限”维附加而得到。<br>\n",
    "要创建netCDF变量，请使用createVariable方法（后文中某个方法都默认为，Dataset或者Group实例中的方法）。该方法具有两个必填参数：变量名称（Python字符串）和变量数据类型。变量的尺寸由包含尺寸名称的元组给定（defined previously with createDimension）。<br>\n",
    "如果要创建标量变量，只需省略Dimensions关键字。<br>\n",
    "变量原始数据类型对应于numpy数组的dtype属性。您可以将数据类型指定为numpy dtype对象，也可以将任何类型转换为numpy dtype对象。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "值得注意的是，维度本身通常也定义为变量，称为坐标变量。该createVariable 方法返回Variable该类的实例，该类的方法可在以后用于访问和设置变量数据和属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意 所有以下的赋值都是python的 视图；而不是拷贝，如果直接修改赋值对象，那么原本的对象也会被改变\n",
    "# 下文的操作都是对语句左侧的 赋值对象\n",
    "times = rootgrp.createVariable(\"time\",\"f8\",(\"time\",)) # 变量名和维度相对应\n",
    "levels = rootgrp.createVariable(\"level\",\"i4\",(\"level\",))\n",
    "latitudes = rootgrp.createVariable(\"lat\",\"f4\",(\"lat\",))\n",
    "longitudes = rootgrp.createVariable(\"lon\",\"f4\",(\"lon\",))\n",
    "# two dimensions unlimited\n",
    "temp = rootgrp.createVariable(\"temp\",\"f4\",(\"time\",\"level\",\"lat\",\"lon\",))\n",
    "temp.units = \"K\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "稍微提一下dtype：<br>\n",
    "有效的数据类型说明符包括：'f4'（32位浮点），'f8'（64位浮点），'i4'（32位带符号整数），'i2'（16位带符号整数），'i8'（64位带符号整数），'i1'（8 位带符号整数）整数），'u1'（8位无符号整数），'u2'（16位无符号整数），'u4'（32位无符号整数），'u8'（64位无符号整数）或'S1'（单字符字符串）<br>\n",
    "旧的数字单字符的TypeCodes（ ，'f'，， 'd''h''s'，'b'，'B'，'c'，'i'，'l'），对应于（'f4'，'f8'，'i2'，'i2'，'i1'，'i1'，'S1'，'i4'，'i4'），也可以工作。仅当文件格式为NETCDF4时才能使用无符号整数类型和64位整数类型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要Variable在交互式会话中获取实例的摘要信息,直接使用print即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 temp(time, level, lat, lon)\n",
      "    units: K\n",
      "unlimited dimensions: time, level\n",
      "current shape = (0, 0, 73, 144)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n"
     ]
    }
   ],
   "source": [
    "print(rootgrp.variables['temp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您可以使用路径在组的层次结构内创建变量。如果中间组尚不存在，则将创建它们。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> ftemp = rootgrp.createVariable(\"/forecasts/model1/temp\",\"f4\",(\"time\",\"level\",\"lat\",\"lon\",))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您也可以直接查询Dataset或Group实例，以使用路径获取Group或 Variable实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Group'>\n",
      "group /forecasts/model1:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): float32 temp(time,level,lat,lon)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    ">>> print(rootgrp[\"/forecasts/model1\"])  # a Group instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 temp(time, level, lat, lon)\n",
      "path = /forecasts/model1\n",
      "unlimited dimensions: time, level\n",
      "current shape = (0, 0, 73, 144)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n"
     ]
    }
   ],
   "source": [
    ">>> print(rootgrp[\"/forecasts/model1/temp\"])  # a Variable instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有在group和Dataset中的变量，以和维度相同方式，存储在一个Python字典："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([<class 'netCDF4._netCDF4.Variable'>\n",
      "float64 time(time)\n",
      "unlimited dimensions: time\n",
      "current shape = (0,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, <class 'netCDF4._netCDF4.Variable'>\n",
      "int32 level(level)\n",
      "unlimited dimensions: level\n",
      "current shape = (0,)\n",
      "filling on, default _FillValue of -2147483647 used, <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 lat(lat)\n",
      "unlimited dimensions: \n",
      "current shape = (73,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 lon(lon)\n",
      "unlimited dimensions: \n",
      "current shape = (144,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 temp(time, level, lat, lon)\n",
      "    units: K\n",
      "unlimited dimensions: time, level\n",
      "current shape = (0, 0, 73, 144)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used])\n"
     ]
    }
   ],
   "source": [
    ">>> print(rootgrp.variables.values()) \n",
    "# rootgrp.variables数据类型为dict，可用一些variables的python1的字典属性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用items遍历所有字典的键值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict_items'>\n",
      "<class 'str'> <class 'netCDF4._netCDF4.Variable'> (0,)\n",
      "<class 'str'> <class 'netCDF4._netCDF4.Variable'> (0,)\n",
      "<class 'str'> <class 'netCDF4._netCDF4.Variable'> (73,)\n",
      "<class 'str'> <class 'netCDF4._netCDF4.Variable'> (144,)\n",
      "<class 'str'> <class 'netCDF4._netCDF4.Variable'> (0, 0, 73, 144)\n"
     ]
    }
   ],
   "source": [
    "print(type(rootgrp.variables.items()))\n",
    "for var_key_test,var_values_test in rootgrp.variables.items():\n",
    "    print(type(var_key_test),type(var_values_test),var_values_test.shape) # 简单输出一下NC4variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用enumerate遍历变量字典中的所有值、序号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,) <class 'netCDF4._netCDF4.Variable'>\n",
      "(0,) <class 'netCDF4._netCDF4.Variable'>\n",
      "(73,) <class 'netCDF4._netCDF4.Variable'>\n",
      "(144,) <class 'netCDF4._netCDF4.Variable'>\n",
      "(0, 0, 73, 144) <class 'netCDF4._netCDF4.Variable'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for var_num,var_values_test in enumerate(rootgrp.variables.values()):\n",
    "    print(var_values_test[:].shape,type(var_values_test)) # 简单输出一下NC4variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable可以使用Dataset实例的renameVariable方法更改名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset.renameVariable(rootgrp,'temp','temp2') #自查官方示例, 还有很多方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font size = 4>netCDF文件中的属性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "netCDF文件中有两种属性，全局属性和变量属性。<br>\n",
    "全局属性提供有关整个group或整个dataset的信息。Variable属性提供有关group中某个变量的信息。<br>\n",
    "全局属性是赋值给Dataset或Group实例变量来设置的。Variable属性通过为Variable实例变量分配值来设置。<br>\n",
    "属性可以是字符串，数字或序列。回到我们的例子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> rootgrp.description = \"bogus example script\"\n",
    ">>> rootgrp.history = \"Created \" + time.ctime(time.time())\n",
    ">>> rootgrp.source = \"netCDF4 python module tutorial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['description', 'history', 'source']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootgrp.ncattrs() # 查看全局属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> latitudes.units = \"degrees north\"\n",
    ">>> longitudes.units = \"degrees east\"\n",
    ">>> levels.units = \"hPa\"\n",
    ">>> temp.units = \"K\"\n",
    ">>> times.units = \"hours since 0001-01-01 00:00:00.0\"\n",
    ">>> times.calendar = \"gregorian\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset，Group或者Variable实例的一个的方法在ncattrs，可用于检索所有的属性的netCDF的名字。提供此方法是为了方便，因为使用内置的 dir 这个Python函数将返回一堆无法（或不应）由用户修改的私有方法和属性。<br>\n",
    "getattr获取rootgrp中name变量的属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global attr description = bogus example script\n",
      "Global attr history = Created Sun Jun  7 16:33:22 2020\n",
      "Global attr source = netCDF4 python module tutorial\n"
     ]
    }
   ],
   "source": [
    ">>> for name in rootgrp.ncattrs():\n",
    "...     print(\"Global attr {} = {}\".format(name, getattr(rootgrp, name)))\n",
    "# rootgrp.ncattrs()\n",
    "# getattr(rootgrp,'history')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset，Group或Variable 实例的一个属性__dict__，提供在Python字典中的所有的netCDF属性名称/值对："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'bogus example script', 'history': 'Created Sun Jun  7 16:33:22 2020', 'source': 'netCDF4 python module tutorial'}\n"
     ]
    }
   ],
   "source": [
    ">>> print(rootgrp.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "netCDF Dataset，group，variable中的属性能被删除，使用 python的del命令（例如：del grp.foo 能去除group grp的foo属性）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font size = 4>向netCDF变量写入数据和从中获取数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在您有了一个netCDF Variable实例，如何将数据放入其中？您可以将其视为数组，然后将数据分配给切片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitudes =\n",
      "[-90.  -87.5 -85.  -82.5 -80.  -77.5 -75.  -72.5 -70.  -67.5 -65.  -62.5\n",
      " -60.  -57.5 -55.  -52.5 -50.  -47.5 -45.  -42.5 -40.  -37.5 -35.  -32.5\n",
      " -30.  -27.5 -25.  -22.5 -20.  -17.5 -15.  -12.5 -10.   -7.5  -5.   -2.5\n",
      "   0.    2.5   5.    7.5  10.   12.5  15.   17.5  20.   22.5  25.   27.5\n",
      "  30.   32.5  35.   37.5  40.   42.5  45.   47.5  50.   52.5  55.   57.5\n",
      "  60.   62.5  65.   67.5  70.   72.5  75.   77.5  80.   82.5  85.   87.5\n",
      "  90. ]\n"
     ]
    }
   ],
   "source": [
    ">>> import numpy\n",
    ">>> lats =  numpy.arange(-90,91,2.5)\n",
    ">>> lons =  numpy.arange(-180,180,2.5)\n",
    "# 注意 latitude 和 longitude 在前文中已经进行了定义\n",
    ">>> latitudes[:] = lats # >>> latitudes = rootgrp.createVariable(\"lat\",\"f4\",(\"lat\",))\n",
    ">>> longitudes[:] = lons # >>> longitudes = rootgrp.createVariable(\"lon\",\"f4\",(\"lon\",))\n",
    ">>> print(\"latitudes =\\n{}\".format(latitudes[:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与NumPy的数组对象不同，Variable 如果您在当前定义的索引范围之外分配数据，则具有无限尺寸的netCDF 对象将沿着这些尺寸增长。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp shape before adding data = (0, 0, 73, 144)\n"
     ]
    }
   ],
   "source": [
    ">>> # append along two unlimited dimensions by assigning to slice.\n",
    ">>> nlats = len(rootgrp.dimensions[\"lat\"])\n",
    ">>> nlons = len(rootgrp.dimensions[\"lon\"])\n",
    ">>> print(\"temp shape before adding data = {}\".format(temp.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp shape after adding data = (5, 10, 73, 144)\n"
     ]
    }
   ],
   "source": [
    ">>> from numpy.random import uniform\n",
    ">>> temp[0:5, 0:10, :, :] = uniform(size=(5, 10, nlats, nlons)) # 注意python中的维度左闭右开；uniform制造个相同维度的数组替换\n",
    ">>> print(\"temp shape after adding data = {}\".format(temp.shape)) # 添加左侧前两个轴为（5，10）\n",
    "# uniform?\n",
    "# print(uniform(size = (5, 10, nlats, lons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意，如同上面将数据附加到temp时，使得temp的level维度增长时，即使尚未将数据分配给level，level变量的大小也会增加。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "levels shape after adding pressure data = (10,)\n"
     ]
    }
   ],
   "source": [
    ">>> # levels have grown, but no values yet assigned.\n",
    ">>> print(\"levels shape after adding pressure data = {}\".format(levels.shape)) # 之前轴大小为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Variable'>\n",
       "int32 level(level)\n",
       "    units: hPa\n",
       "unlimited dimensions: level\n",
       "current shape = (10,)\n",
       "filling on, default _FillValue of -2147483647 used"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> # now, assign data to levels dimension variable.\n",
    ">>> levels[:] =  [1000.,850.,700.,500.,300.,250.,200.,150.,100.,50.]\n",
    "levels # class 是变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意下前文中定义的level维度 和 levels变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level is rootgrp.dimensions['level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels is rootgrp.variables['level']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是，NumPy和netCDF变量切片规则之间存在一些差异。<br>\n",
    "切片的行为与往常一样，指定为 start:stop:step三元组。使用标量整数索引i采用第i个元素，并将输出数组的rank降低1。(轴减少1？)<br>\n",
    "布尔数组和整数序列索引对于netCDF变量的行为不同于对numpy数组。仅允许使用一维布尔数组和整数序列，并且这些索引在每个维度上均独立工作（类似于矢量下标在fortran中的工作方式）。这意味着下面示例中的[0,1,2,3]中的0将对应后一个维度中的所有[0,1,2,3]而不仅仅是[0]:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> temp[0, 0, [0,1,2,3], [0,1,2,3]].shape # rank减少了，唯一指定的维度消失\n",
    "# temp[0, 0, 0:4, 0:4].shape # 与上文相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对netCDF变量进行切片时，将返回形状数组（4,4），但对于numpy数组，它将返回形状数组（4，）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy中如果要实现相同功能，需使用slices\n",
      "shape为:(4, 4)\n"
     ]
    }
   ],
   "source": [
    "temp_in_np = numpy.array(temp)\n",
    "# temp_in_np.shape\n",
    "print(\"numpy中如果要实现相同功能，需使用slices\\nshape为:{}\".format(temp_in_np[0, 0, 0:4, 0:4].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy中如果使用indicates为四个元素\n",
      ":(4,)\n"
     ]
    }
   ],
   "source": [
    "temp_in_np = numpy.array(temp)\n",
    "# temp_in_np.shape\n",
    "print(\"numpy中如果使用indicates为四个元素\\n:{}\".format(temp_in_np[0, 0, [0,1,2,3], [0,1,2,3]].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类似地，使用(2,3,4,5)索引的形状的netCDF变量[0, array([True, False, True]), array([False, True, True, True]), :] 将返回一个(2, 3, 5)数组。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在NumPy中，这将引发一个错误，因为它等效于[0, [0,1], [1,2,3], :],如在下面的示例中:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 5)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array_test1 = numpy.zeros(shape = (2,3,4,5))\n",
    "# np_array_test1[0,[0,1],[1,2,3],:] # shape mismatch!提取不出对应元素\n",
    "np_array_test1[0,:2,:3,:].shape # numpy中正确写法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以在netCDF变量中，使用整数序列切片时，索引**不需要排序**，并且**可以包含重复项**（这两者都是1.2.1版中的新功能）。<br>虽然此行为可能会使习惯于NumPy的“花式索引”规则的人感到困惑，但它提供了一种非常强大的方法，可以通过**对维数组使用逻辑运算**来创建切片，从而从多维netCDF变量中提取数据。<br>\n",
    "例如:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 36, 71)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> tempdat = temp[::2, [1,3,6], lats>0, lons>0]\n",
    "tempdat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将提取时间指标0、2和4，压力水平850、500和200 hPa，所有北半球纬度和东半球经度，从而得到形状为（3、3、36、71）的数个数组。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**标量变量的特别说明**：要从v无关联维的标量变量中提取数据 ，请使用numpy.asarray(v)或v[...]。结果将是一个numpy标量数组。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "默认情况下，netcdf4-python返回numpy屏蔽数组，其值等于 missing_value或_FillValue屏蔽的变量属性。<br>\n",
    "set_auto_mask方法可以被用于取消这种特性，使numpy数组始终带着missing values返回。<br>\n",
    "在1.4.0之前的版本中，默认行为是仅在请求的切片包含缺失值时才返回掩码数组。可以使用set_always_mask方法恢复此特性。<br>\n",
    "如果将掩码数组写入netCDF变量，则掩码元素将由属性指定的missing_value填充。<br>\n",
    "相对的，如果变量没有missing_value, fill_values会被使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 36, 71)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tempdat)\n",
    "# numpy.count_nonzero(numpy.isnan(tempdat)) # 查询缺失值\n",
    "tempdat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Group\n",
    "Group.set_always_mask(rootgrp,False)\n",
    "tempdat_test1 = temp[::2, [1,3,6], lats>0, lons>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font size =4 >处理时间坐标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "时间坐标值给netCDF用户带来了特殊的挑战。大多数元数据标准（例如CF）指定使用特定日历相对于固定日期测量时间，单位指定为**hours since YY-MM-DD hh:mm:ss**。在没有实用程序将值与日历日期之间进行转换的情况下，这些单位可能很难处理。<br>\n",
    "该函数调用**num2date**和**date2num**配备有这个包来做到这一点（从1.4.0版本中， **cftim**e包必须单独安装）。以下是如何使用它们的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> # fill in times.\n",
    ">>> from datetime import datetime, timedelta # remains\n",
    ">>> from netCDF4 import num2date, date2num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> dates = [datetime(2001,3,1)+n*timedelta(hours=12) for n in range(temp.shape[0])]\n",
    "datetime # 以2001.3.1起始点， 间隔12小时生成时间坐标;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> times[:] = date2num(dates,units=times.units,calendar=times.calendar) # 将datetime日期转换为NC式的units+起点的形式\n",
    "# getattr(times, 'units')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time values (in units hours since 0001-01-01 00:00:00.0):\n",
      "[17533104. 17533116. 17533128. 17533140. 17533152.]\n"
     ]
    }
   ],
   "source": [
    ">>> print(\"time values (in units {}):\\n{}\".format(times.units, times[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates corresponding to time values:\n",
      "[cftime.DatetimeGregorian(2001-03-01 00:00:00)\n",
      " cftime.DatetimeGregorian(2001-03-01 12:00:00)\n",
      " cftime.DatetimeGregorian(2001-03-02 00:00:00)\n",
      " cftime.DatetimeGregorian(2001-03-02 12:00:00)\n",
      " cftime.DatetimeGregorian(2001-03-03 00:00:00)]\n"
     ]
    }
   ],
   "source": [
    ">>> dates = num2date(times[:],units=times.units,calendar=times.calendar) # 将NC式时间转换为cftime的形式\n",
    ">>> print(\"dates corresponding to time values:\\n{}\".format(dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**num2date**转换的指定时间的数字值units和calendar为datetime对象，**date2num**则相反。<br>\n",
    "支持当前在CF元数据约定中定义的所有日历 。还提供了一个称为**date2index**的函数，该函数返回与日期时间实例序列相对应的netCDF时间变量的索引。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font size = 4>从多文件netCDF数据集中读取数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果要从跨越多个netCDF文件的变量中读取数据，则可以使用**MFDataset类**来读取数据，就好像它们包含在单个文件中一样。<br>\n",
    "不要使用单个文件名创建Dataset实例，而是使用文件名MFDataset列表或带有通配符的字符串创建一个实例（然后使用python glob模块将其转换为文件的排序列表）。<br>\n",
    "共享相同无限尺寸的文件列表中的变量将汇总在一起，并且可以跨多个文件进行切片。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了说明这一点，让我们首先创建一堆具有相同变量（具有相同的无限尺寸）的netCDF文件。该文件必须是NETCDF3_64BIT_OFFSET，NETCDF3_64BIT_DATA，NETCDF3_CLASSIC或 NETCDF4_CLASSIC格式（NETCDF4格式化多文件数据集不支持）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> for nf in range(10):\n",
    "...     with Dataset(\"./test_files/mftest%s.nc\" % nf, \"w\", format=\"NETCDF4_CLASSIC\") as f: # with 不需要close\n",
    "...         _ = f.createDimension(\"x\",None)\n",
    "...         x = f.createVariable(\"x\",\"i\",(\"x\",))\n",
    "...         x[0:10] = numpy.arange(nf*10,10*(nf+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在使用MFDataset一次性读入所有文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99]\n"
     ]
    }
   ],
   "source": [
    ">>> from netCDF4 import MFDataset\n",
    ">>> f = MFDataset(\"./test_files/mftest*nc\")\n",
    ">>> print(f.variables[\"x\"][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.MFDataset'>\n",
       "root group (NETCDF4_CLASSIC data model, file format HDF5):\n",
       "    dimensions = ('x',)\n",
       "    variables = ('x',)\n",
       "    groups = ()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.variables['x'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果需要将每个文件的dataset类相互分开，可考虑用glob配合多个文件的读入 :Unix样式路径名模式扩展"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# glob.glob?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./test_files/mftest0.nc', './test_files/mftest1.nc']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mftest_path = glob.glob('./test_files//mftest*.nc')\n",
    "mftest_path[0:2] # 简单展示两个文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<class 'netCDF4._netCDF4.Dataset'>\n",
       " root group (NETCDF4_CLASSIC data model, file format HDF5):\n",
       "     dimensions(sizes): x(10)\n",
       "     variables(dimensions): int32 x(x)\n",
       "     groups: ,\n",
       " <class 'netCDF4._netCDF4.Dataset'>\n",
       " root group (NETCDF4_CLASSIC data model, file format HDF5):\n",
       "     dimensions(sizes): x(10)\n",
       "     variables(dimensions): int32 x(x)\n",
       "     groups: ]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enumerate? \n",
    "fh_list = []\n",
    "#enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列\n",
    "# 同时列出数据和数据下标，一般用在 for 循环\n",
    "list(enumerate(mftest_path))\n",
    "for timestep, datafile in enumerate(mftest_path): # timestep没用上其实\n",
    "    fh_list.append(Dataset(datafile,mode='r'))  \n",
    "fh_list[0:2] # 直接用列表装多个Dataset即可,简单展示两个"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font size=4>有效压缩netCDF变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "netCDF 4 Variable对象中存储的数据可以动态压缩和解压缩。<br>\n",
    "用于决定压缩参数的关键字有**zlib**，**complevel**，**shuffle**，来源于**createVariable**方法。<br>\n",
    "要打开压缩，先设置**zlib=True**,**complevel**关键字调节压缩的速度和效率（1是最快的，但压缩率最低，9是最慢的，压缩比最高），默认**complevel=4**<br>\n",
    "设置**shuffle=False**将关闭HDF5混洗过滤器(shuffle filter)，该过滤器会在压缩之前通过对字节重新排序来对数据块进行去隔行处理。混洗过滤器(shuffle filter)可以显著地提高压缩率<br>\n",
    "将**createVariable**的**fletcher32**关键字参数设置为**True**（默认情况下为**False**）来启用**Fletcher32**校验和算法进行错误检测。<br>\n",
    "还可以使用**createVariable**中的**chunksizes**和**endian**关键字参数，设置HDF5分块参数和存储在HDF5文件中的二进制数据的字节序。这些关键字参数仅是相关的NETCDF4和NETCDF4_CLASSIC文件（其中潜在的文件格式是HDF5），如果文件格式是NETCDF3_CLASSIC，NETCDF3_64BIT_OFFSET或NETCDF3_64BIT_DATA则会被忽略。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果您的数据仅具有一定数量的精度（例如，以0.1度的精度测量的温度数据），则可以通过使用createVariable中的**least_significant_digit**关键字参数，量化（或截断）数据来显着改善**zlib**压缩。<br>\n",
    "最低有效位是数据中最小小数点后十位的幂，它是一个可靠的值。<br>\n",
    "例如，如果数据的精度为0.1，则设置**least_significant_digit=1**,将使用量化数据**numpy.around(scale*data)/scale**，其中**scale = 2 ** bits**，并且确定位以使精度保持为0.1 ***（在这种情况下，bits = 4 ）***。实际上，这使压缩成为“有损”而不是“无损”，也就是说，为了节省磁盘空间而牺牲了一些精度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在我们的示例中，新建一个temp_nonzlib变量（说明未压缩的情况）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Variable'>\n",
       "float32 temp_nonzlib(time, level, lat, lon)\n",
       "unlimited dimensions: time, level\n",
       "current shape = (5, 10, 73, 144)\n",
       "filling on, default _FillValue of 9.969209968386869e+36 used"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> temp_nonzlib = rootgrp.createVariable(\"temp_nonzlib\",\"f4\",(\"time\",\"level\",\"lat\",\"lon\",))\n",
    "temp_nonzlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面创建压缩后的变量temp_zlib1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Variable'>\n",
       "float32 temp_zlib1(time, level, lat, lon)\n",
       "unlimited dimensions: time, level\n",
       "current shape = (5, 10, 73, 144)\n",
       "filling on, default _FillValue of 9.969209968386869e+36 used"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> temp_test_zlib = rootgrp.createVariable(\"temp_zlib1\",\"f4\",(\"time\",\"level\",\"lat\",\"lon\",),zlib=True)\n",
    "temp_test_zlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以及不同压缩形式的变量temp_zlib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Variable'>\n",
       "float32 temp_zlib2(time, level, lat, lon)\n",
       "    least_significant_digit: 3\n",
       "unlimited dimensions: time, level\n",
       "current shape = (5, 10, 73, 144)\n",
       "filling on, default _FillValue of 9.969209968386869e+36 used"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> temp_test_zlib2 = rootgrp.createVariable(\"temp_zlib2\",\"f4\",(\"time\",\"level\",\"lat\",\"lon\",),zlib=True,least_significant_digit=3)\n",
    "temp_test_zlib2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可查看一下zlib2和zlib之间的大小的差异。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 超越固定类型的均值数组：复合数据类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "复合数据类型直接映射到numpy结构化（也称为“record”）数组。<br>\n",
    "结构化数组类似于C结构或Fortran中的派生类型。它们允许构造由其他数据类型（包括其他复合类型）的组合组成的表状结构。复合类型对于在网格上的每个点或在分散的（点）数据的每个时间和空间位置表示多个参数值可能很有用。然后，您可以通过读取一个变量来访问某个点的所有信息，而不是从不同的变量中读取不同的参数。<br>\n",
    "使用```Dataset```或者```group```实例的```createCompoundTypea```方法从相应的numpy数据类型创建复合数据类型。<br>\n",
    "由于netcdf中没有本机复杂数据类型，因此复合类型非常适合存储numpy复杂数组。这是一个例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complex128: [ 0.54030231+0.84147098j -0.84147098+0.54030231j -0.54030231-0.84147098j]\n",
      "complex128: [ 0.54030231+0.84147098j -0.84147098+0.54030231j -0.54030231-0.84147098j]\n"
     ]
    }
   ],
   "source": [
    ">>> f = Dataset(\"complex.nc\",\"w\")\n",
    ">>> size = 3 # length of 1-d complex array\n",
    ">>> # create sample complex data.\n",
    ">>> datac = numpy.exp(1j*(1.+numpy.linspace(0, numpy.pi, size)))\n",
    ">>> # create complex128 compound data type.\n",
    ">>> complex128 = numpy.dtype([(\"real\",numpy.float64),(\"imag\",numpy.float64)])\n",
    ">>> complex128_t = f.createCompoundType(complex128,\"complex128\")\n",
    ">>> # create a variable with this data type, write some data to it.\n",
    ">>> x_dim = f.createDimension(\"x_dim\",None)\n",
    ">>> v = f.createVariable(\"cmplx_var\",complex128_t,\"x_dim\")\n",
    ">>> data = numpy.empty(size,complex128) # numpy structured array\n",
    ">>> data[\"real\"] = datac.real; data[\"imag\"] = datac.imag\n",
    ">>> v[:] = data # write numpy structured array to netcdf compound var\n",
    ">>> # close and reopen the file, check the contents.\n",
    ">>> f.close(); f = Dataset(\"complex.nc\")\n",
    ">>> v = f.variables[\"cmplx_var\"]\n",
    ">>> datain = v[:] # read in all the data into a numpy structured array\n",
    ">>> # create an empty numpy complex array\n",
    ">>> datac2 = numpy.empty(datain.shape,numpy.complex128)\n",
    ">>> # .. fill it with contents of structured array.\n",
    ">>> datac2.real = datain[\"real\"]; datac2.imag = datain[\"imag\"]\n",
    ">>> print('{}: {}'.format(datac.dtype, datac)) # original data\n",
    ">>> print('{}: {}'.format(datac2.dtype, datac2)) # data from file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "复合类型可以嵌套，但是您必须首先创建“内部”类型。所有可能的numpy结构化数组都不能表示为复合变量-如果尝试创建不支持的数组，则会出现错误消息。为Dataset或定义的所有复合类型Group都存储在Python字典中，就像变量和尺寸一样。与往常一样，打印对象在交互式会话中提供有用的摘要信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    dimensions(sizes): x_dim(3)\n",
      "    variables(dimensions): {'names':['real','imag'], 'formats':['<f8','<f8'], 'offsets':[0,8], 'itemsize':16, 'aligned':True} cmplx_var(x_dim)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "compound cmplx_var(x_dim)\n",
      "compound data type: {'names':['real','imag'], 'formats':['<f8','<f8'], 'offsets':[0,8], 'itemsize':16, 'aligned':True}\n",
      "unlimited dimensions: x_dim\n",
      "current shape = (3,)\n"
     ]
    }
   ],
   "source": [
    "print(f.variables[\"cmplx_var\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'complex128': <class 'netCDF4._netCDF4.CompoundType'>: name = 'complex128', numpy dtype = {'names':['real','imag'], 'formats':['<f8','<f8'], 'offsets':[0,8], 'itemsize':16, 'aligned':True}}\n"
     ]
    }
   ],
   "source": [
    "print(f.cmptypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.CompoundType'>: name = 'complex128', numpy dtype = {'names':['real','imag'], 'formats':['<f8','<f8'], 'offsets':[0,8], 'itemsize':16, 'aligned':True}\n"
     ]
    }
   ],
   "source": [
    "print(f.cmptypes[\"complex128\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font size = 4>可变长度（vlen）数据类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NetCDF 4支持可变长度或“参差不齐”的阵列。这些是具有相同类型的可变长度序列的数组。要创建长度可变的数据类型，请使用Dataset或Group实例的**createVLTypemethod**方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> f = Dataset(\"tst_vlen.nc\",\"w\")\n",
    ">>> vlen_t = f.createVLType(numpy.int32, \"phony_vlen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必须指定可变长度序列的numpy数据类型和新数据类型的名称。可以使用任何原始数据类型（有符号和无符号整数，32位和64位浮点数以及字符），但是复合数据类型则不能。然后可以使用此数据类型创建一个新变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> x = f.createDimension(\"x\",3)\n",
    ">>> y = f.createDimension(\"y\",4)\n",
    ">>> vlvar = f.createVariable(\"phony_vlen_var\", vlen_t, (\"y\",\"x\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于numpy中没有本机vlen数据类型，因此vlen数组在python中表示为对象数组（dtype的数组object）。这些是数组，其元素是Python对象指针，并且可以包含任何类型的python对象。<br>\n",
    "对于此应用程序，它们必须包含全部具有相同类型但长度不同的一维numpy数组。在这种情况下，它们包含一维numpy int32数组，其随机长度在1到10之间。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import random\n",
    ">>> random.seed(54321)\n",
    ">>> data = numpy.empty(len(y)*len(x),object)\n",
    ">>> for n in range(len(y)*len(x)):\n",
    "...     data[n] = numpy.arange(random.randint(1,10),dtype=\"int32\")+1\n",
    ">>> data = numpy.reshape(data,(len(y),len(x)))\n",
    ">>> vlvar[:] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vlen variable =\n",
      "[[array([1, 2, 3, 4, 5, 6, 7, 8], dtype=int32) array([1, 2], dtype=int32)\n",
      "  array([1, 2, 3, 4], dtype=int32)]\n",
      " [array([1, 2, 3], dtype=int32)\n",
      "  array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)\n",
      "  array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)]\n",
      " [array([1, 2, 3, 4, 5, 6, 7], dtype=int32) array([1, 2, 3], dtype=int32)\n",
      "  array([1, 2, 3, 4, 5, 6], dtype=int32)]\n",
      " [array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)\n",
      "  array([1, 2, 3, 4, 5], dtype=int32) array([1, 2], dtype=int32)]]\n"
     ]
    }
   ],
   "source": [
    ">>> print(\"vlen variable =\\n{}\".format(vlvar[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    dimensions(sizes): x(3), y(4)\n",
      "    variables(dimensions): int32 phony_vlen_var(y,x)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    ">>> print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "vlen phony_vlen_var(y, x)\n",
      "vlen data type: int32\n",
      "unlimited dimensions: \n",
      "current shape = (4, 3)\n"
     ]
    }
   ],
   "source": [
    ">>> print(f.variables[\"phony_vlen_var\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.VLType'>: name = 'phony_vlen', numpy dtype = int32\n"
     ]
    }
   ],
   "source": [
    ">>> print(f.vltypes[\"phony_vlen\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "包含python字符串的Numpy对象数组也可以写为vlen变量。<br>\n",
    "对于vlen字符串，您无需创建vlen数据类型。相反，str在调用createVariable方法时，只需使用python 内置函数（或固定长度大于1的numpy字符串数据类型）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> z = f.createDimension(\"z\",10)\n",
    ">>> strvar = f.createVariable(\"strvar\", str, \"z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在此示例中，对象数组中填充了2至12个字符之间的随机长度的随机python字符串，并将对象数组中的数据分配给vlen字符串变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> chars = \"1234567890aabcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    ">>> data = numpy.empty(10,\"O\")\n",
    ">>> for n in range(10):\n",
    "...     stringlen = random.randint(2,12)\n",
    "...     data[n] = \"\".join([random.choice(chars) for i in range(stringlen)])\n",
    ">>> strvar[:] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable-length string variable:\n",
      "['Lh' '25F8wBbMI' '53rmM' 'vvjnb3t63ao' 'qjRBQk6w' 'aJh' 'QF'\n",
      " 'jtIJbJACaQk4' '3Z5' 'bftIIq']\n",
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    dimensions(sizes): x(3), y(4), z(10)\n",
      "    variables(dimensions): int32 phony_vlen_var(y,x), <class 'str'> strvar(z)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    ">>> print(\"variable-length string variable:\\n{}\".format(strvar[:]))\n",
    ">>> print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    dimensions(sizes): x(3), y(4), z(10)\n",
      "    variables(dimensions): int32 phony_vlen_var(y,x), <class 'str'> strvar(z)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    ">>> print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "vlen strvar(z)\n",
      "vlen data type: <class 'str'>\n",
      "unlimited dimensions: \n",
      "current shape = (10,)\n"
     ]
    }
   ],
   "source": [
    ">>> print(f.variables[\"strvar\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以使用任何字符串或Unicode数据类型的numpy数组设置vlen字符串变量的内容。但是请注意，访问此类变量的内容将始终返回带有dtype的numpy数组object。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 枚举数据类型（Enum data type）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "netCDF4具有枚举数据类型，它是一种整数数据类型，仅限于某些特定命名值。由于枚举不会直接映射到numpy数据类型，因此它们将被读取和写入为整数数组。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是使用Enum类型保存云类型数据的示例。<br>\n",
    "将基本整数数据类型和包含允许值及其名称的python字典，通过createEnumType，定义一个Enum数据类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> nc = Dataset('clouds.nc','w')\n",
    ">>> # python dict with allowed values and their names.\n",
    ">>> enum_dict = {'Altocumulus': 7, 'Missing': 255,\n",
    "... 'Stratus': 2, 'Clear': 0,\n",
    "... 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5,\n",
    "... 'Cumulonimbus': 1, 'Stratocumulus': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Altocumulus': 7,\n",
       " 'Missing': 255,\n",
       " 'Stratus': 2,\n",
       " 'Clear': 0,\n",
       " 'Nimbostratus': 6,\n",
       " 'Cumulus': 4,\n",
       " 'Altostratus': 5,\n",
       " 'Cumulonimbus': 1,\n",
       " 'Stratocumulus': 3}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enum_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> # create the Enum type called 'cloud_t'.\n",
    ">>> cloud_type = nc.createEnumType(numpy.uint8,'cloud_t',enum_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.EnumType'>: name = 'cloud_t', numpy dtype = uint8, fields/values ={'Altocumulus': 7, 'Missing': 255, 'Stratus': 2, 'Clear': 0, 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 'Cumulonimbus': 1, 'Stratocumulus': 3}\n"
     ]
    }
   ],
   "source": [
    ">>> print(cloud_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~也可以用下面的查询 cloud_var 类型的方式：~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以使用此数据类型以常规方式创建新变量。<br>\n",
    "将整数数据写入代表字典enum_dict中命名的云类型的变量。<br>\n",
    "如果尝试写入与指定名称之一不相关的整数值，则将引发ValueError。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是示例，先进行cloud_var变量的创建(使其包含上述enum_dict字典):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> time = nc.createDimension('time',None)\n",
    ">>> # create a 1d variable of type 'cloud_type'.\n",
    ">>> # The fill_value is set to the 'Missing' named value.\n",
    ">>> cloud_var = nc.createVariable('primary_cloud',cloud_type,'time',\n",
    "...                               fill_value=enum_dict['Missing'])  \n",
    "#  此处初始化的三个量同时也是cloud_var.*的三个实例\n",
    ">>> # write some data to the variable.\n",
    ">>> cloud_var[:] = [enum_dict[k] for k in ['Clear', 'Stratus', 'Cumulus',\n",
    "...                                        'Missing', 'Cumulonimbus']]\n",
    ">>> nc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "enum primary_cloud(time)\n",
      "    _FillValue: 255\n",
      "enum data type: uint8\n",
      "unlimited dimensions: time\n",
      "current shape = (5,)\n"
     ]
    }
   ],
   "source": [
    ">>> # reopen the file, read the data.\n",
    ">>> nc = Dataset('clouds.nc')\n",
    ">>> cloud_var = nc.variables['primary_cloud']  # 观察数据类型\n",
    ">>> print(cloud_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.EnumType'>: name = 'cloud_t', numpy dtype = uint8, fields/values ={'Altocumulus': 7, 'Missing': -1, 'Stratus': 2, 'Clear': 0, 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 'Cumulonimbus': 1, 'Stratocumulus': 3}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloud_var.datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cloud_t'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloud_var.datatype.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Altocumulus': 7, 'Missing': -1, 'Stratus': 2, 'Clear': 0, 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 'Cumulonimbus': 1, 'Stratocumulus': 3}\n"
     ]
    }
   ],
   "source": [
    ">>> print(cloud_var.datatype.enum_dict)  # 刚才写入的字典，已经是一个实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 4 -- 1]\n"
     ]
    }
   ],
   "source": [
    ">>> print(cloud_var[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> nc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 并行I/O（remains：未安装scipy库，先进行翻译）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果**NetCDF**、**HDF5**、**pnetcdf**的***MPI**并行（MPI parallel）启用的版本被检测到，并且**mpi4py**已安装，**netcdf4-python**的并行IO能力将会启用。<br>\n",
    "仅当**MPI parallel HDF5**库可用时，才可以使用NETCDF4或NETCDF4_CLASSIC格式的文件的并行IO。<br>\n",
    "仅当PnetCDF库可用时，经典netcdf-3文件格式的并行IO才可用。<br>\n",
    "要使用并行IO，您的程序必须使用mpi4py且在MPI环境中运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mpi4py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-43eea07a7baf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmpi4py\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMPI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnetCDF4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMPI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMM_WORLD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m  \u001b[0;31m# The process ID (integer 0-3 for 4-process run)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mpi4py'"
     ]
    }
   ],
   "source": [
    ">>> from mpi4py import MPI\n",
    ">>> import numpy as np\n",
    ">>> from netCDF4 import Dataset\n",
    ">>> rank = MPI.COMM_WORLD.rank  # The process ID (integer 0-3 for 4-process run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要像这样运行基于MPI的并行程序，必须使用它**mpiexec**来启动多个Python并行实例<br>\n",
    "（例如，使用```mpiexec -np 4 python mpi_example.py）```。\n",
    "netcdf4-python的并行功能大部分是透明的——即是说，创建新数据集或打开现有数据集时，请使用```parallel```关键字启用并行访问。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "parallel mode requires MPI enabled netcdf-c",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-f9ffcfa5428b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'parallel_test.nc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: parallel mode requires MPI enabled netcdf-c"
     ]
    }
   ],
   "source": [
    ">>> nc = Dataset('parallel_test.nc','w',parallel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可选```comm```关键字可用于指定特定的MPI通信器（communicator）（```MPI_COMM_WORLD```在默认情况下使用）。<br>\n",
    "现在，每个进程（或rank）都可以独立地写入文件。<br>\n",
    "在下面的示例中，流程rank被写入每个任务的不同变量索引:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "NetCDF: Not a valid ID",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-6361a4511a72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dim'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'var'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.createDimension\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dimension.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NetCDF: Not a valid ID"
     ]
    }
   ],
   "source": [
    ">>> d = nc.createDimension('dim',4)\n",
    ">>> v = nc.createVariable('var', np.int, 'dim')\n",
    ">>> v[rank] = rank\n",
    ">>> nc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "% ncdump parallel_test.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有两种类型的并行IO：独立（independent）（默认）和集合（collective）IO。<br>\n",
    "独立IO意味着每个进程都可以独立执行IO。它不应依赖于其他进程或受其影响。<br>\n",
    "集体IO是一种执行MPI-IO标准中定义的IO的方法；与独立IO不同，所有进程都必须参与IO。<br>\n",
    "要在两种类型的IO之间来回切换，请使用方法```set_collective Variable```。所有元数据操作（例如组，类型，变量，维或属性的创建）都是集合的。<br>\n",
    "并行IO有几个重要限制：\n",
    "* NETCDF4或NETCDF4_CLASSIC格式的文件的并行IO仅在netcdf库与启用MPI的HDF5一起编译时可用。\n",
    "* 仅当netcdf库是使用PnetCDF编译时，才可以使用所有经典netcdf-3文件格式的并行IO。\n",
    "* 如果变量的大小不受限制，则必须以集合模式添加数据。如果写入是在独立模式下完成的，则操作将失败，并显示通用的“ HDFerror”。\n",
    "* 您不能并行写入压缩数据（尽管可以读取）。\n",
    "* 您不能使用可变长度（VLEN）数据类型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "存储字符串数组最灵活的方法是使用 可变长度（vlen）字符串数据类型。但是，这需要使用NETCDF4数据模型，并且vlen类型不能很好地映射numpy数组（您必须使用dtype =```object```的numpy数组，它们是任意python对象的数组）。numpy具有固定宽度(fixed-width)的字符串数组数据类型，但不幸的是netCDF数据模型没有。相反，固定宽度的字节字符串通常存储为8位字符数组。<br>\n",
    "要执行从字符数组到固定宽度numpy字符串数组的转换，python接口遵循以下约定:<br>\n",
    "如果```_Encoding```为字符数组（dtype ```S1```）变量设置了特殊属性，则```chartostring```实用程序(utillity function)函数用于在读取数据时将字符数组转换为较小一维（最后一个维解释为每个字符串的长度）的字符串数组。<br>\n",
    "字符集（通常为ascii）由```_Encoding```属性指定。如果```_Encoding``` 为'none'或'bytes'，则字符数组将转换为numpy固定宽度字节字符串数组（dtype S#），否则将创建numpy unicode（dtype ```U#```）数组。<br>\n",
    "写入数据时， ```stringtochar```用于将numpy字符串数组转换为一维的字符数组。例如，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from netCDF4 import stringtochar\n",
    ">>> nc = Dataset('stringtest.nc','w',format='NETCDF4_CLASSIC')\n",
    ">>> _ = nc.createDimension('nchars',3)\n",
    ">>> _ = nc.createDimension('nstrings',None)\n",
    ">>> v = nc.createVariable('strings','S1',('nstrings','nchars'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF4_CLASSIC data model, file format HDF5):\n",
       "    dimensions(sizes): nchars(3), nstrings(0)\n",
       "    variables(dimensions): |S1 strings(nstrings,nchars)\n",
       "    groups: "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> datain = numpy.array(['foo','bar'],dtype='S3')\n",
    ">>> v[:] = stringtochar(datain) # manual conversion to char array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'f' b'o' b'o']\n",
      " [b'b' b'a' b'r']]\n"
     ]
    }
   ],
   "source": [
    ">>> print(v[:]) # data returned as char array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['foo' 'bar']\n"
     ]
    }
   ],
   "source": [
    ">>> v._Encoding = 'ascii' # this enables automatic conversion\n",
    ">>> v[:] = datain # conversion to char array done internally\n",
    ">>> print(v[:])  # data returned in numpy string array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "即使```_Encoding```属性被设置了，也可以使用```set_auto_chartostring```禁用将char数组自动转换为字符串数组或从string数组自动转换的功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy结构化数组经常遇到类似情况，其子类型包含固定wdith字节字符串（dtype = S#）。由于没有本地固定长度的字符串netCDF数据类型，因此这些numpy结构数组将通过字符数组元素映射到netCDF复合类型。<br>\n",
    "在这种情况下， 使用numpy views自动处理字符串<->char数组转换（无需设置```_Encoding```属性）。<br>\n",
    "结构化数组dtype（包括字符串元素）甚至可以用于定义复合数据类型——在创建netcdf复合类型时，字符串dtype将在幕后(under the hood?)转换为字符数组dtype。<br>\n",
    "这是一个例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> nc = Dataset('compoundstring_example.nc','w')\n",
    ">>> dtype = numpy.dtype([('observation', 'f4'),\n",
    "...                      ('station_name','S10')])\n",
    "\n",
    ">>> station_data_t = nc.createCompoundType(dtype,'station_data')\n",
    ">>> _ = nc.createDimension('station',None)\n",
    ">>> statdat = nc.createVariable('station_obs', station_data_t, ('station',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> data = numpy.empty(2,dtype)\n",
    ">>> data['observation'][:] = (123.,3.14)\n",
    ">>> data['station_name'][:] = ('Boulder','New York')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'names':['observation','station_name'], 'formats':['<f4',('S1', (10,))], 'offsets':[0,4], 'itemsize':16, 'aligned':True}\n"
     ]
    }
   ],
   "source": [
    ">>> print(statdat.dtype) # strings actually stored as character arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(123.  , b'Boulder') (  3.14, b'New York')]\n"
     ]
    }
   ],
   "source": [
    ">>> statdat[:] = data # strings converted to character arrays internally\n",
    ">>> print(statdat[:])  # character arrays converted back to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'names':['observation','station_name'], 'formats':['<f4','S10'], 'offsets':[0,4], 'itemsize':16, 'aligned':True}\n"
     ]
    }
   ],
   "source": [
    ">>> print(statdat[:].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> statdat.set_auto_chartostring(False) # turn off auto-conversion\n",
    ">>> statdat[:] = data.view(dtype=[('observation', 'f4'),('station_name','S1',10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(123.  , [b'B', b'o', b'u', b'l', b'd', b'e', b'r', b'', b'', b''])\n",
      " (  3.14, [b'N', b'e', b'w', b' ', b'Y', b'o', b'r', b'k', b'', b''])]\n"
     ]
    }
   ],
   "source": [
    "print(statdat[:]) # now structured array with char array subtype is returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意，当前不支持将具有unicode元素（dtype U#）的numpy结构化数组映射到netCDF复合类型，也不支持具有vlen字符串组件的netCDF复合类型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# in-memory(diskless) 数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您可以创建netCDF数据集，其内容保存在内存中而不是磁盘文件中。有两种方法可以做到这一点。<br>\n",
    "如果您不需要从python内部访问包含数据集的内存缓冲区，最好的方法是在创建数据集时使用关键字参数```diskless=True```。<br>\n",
    "如果要在关闭数据集时将其保存到磁盘，请同时设置```persist=True```。<br>\n",
    "如果要从现有的python内存缓冲区创建新的只读数据集，请在创建数据集时使用关键字参数```memory```传递内存缓冲区。<br>\n",
    "如果要创建一个新的内存中数据集，然后直接从Python访问内存缓冲区，请在创建带有```mode='w'```数据集时使用关键字参数```memory```指定数据集的估计大小（以字节为单位）。然后，```Dataset.close```方法将返回代表数据集的python memoryview对象。<br>\n",
    "以下是说明这两种方法的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    dimensions(sizes): x(5)\n",
      "    variables(dimensions): int32 v(x)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    ">>> # create a diskless (in-memory) Dataset,\n",
    ">>> # and persist the file to disk when it is closed.\n",
    ">>> nc = Dataset('diskless_example.nc','w',diskless=True,persist=True)\n",
    ">>> d = nc.createDimension('x',None)\n",
    ">>> v = nc.createVariable('v',numpy.int32,'x')\n",
    ">>> v[0:5] = numpy.arange(5)\n",
    ">>> print(nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    ">>> print(nc['v'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> nc.close() # file saved to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    dimensions(sizes): x(5)\n",
      "    variables(dimensions): int32 v(x)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    ">>> # create an in-memory dataset from an existing python\n",
    ">>> # python memory buffer.\n",
    ">>> # read the newly created netcdf file into a python\n",
    ">>> # bytes object.\n",
    ">>> with open('diskless_example.nc', 'rb') as f:\n",
    "...     nc_bytes = f.read()\n",
    ">>> # create a netCDF in-memory dataset from the bytes object.\n",
    ">>> nc = Dataset('inmemory.nc', memory=nc_bytes)\n",
    ">>> print(nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    ">>> print(nc['v'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> nc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'memoryview'>\n"
     ]
    }
   ],
   "source": [
    ">>> # create an in-memory Dataset and retrieve memory buffer\n",
    ">>> # estimated size is 1028 bytes - this is actually only\n",
    ">>> # used if format is NETCDF3\n",
    ">>> # (ignored for NETCDF4/HDF5 files).\n",
    ">>> nc = Dataset('inmemory.nc', mode='w',memory=1028)\n",
    ">>> d = nc.createDimension('x',None)\n",
    ">>> v = nc.createVariable('v',numpy.int32,'x')\n",
    ">>> v[0:5] = numpy.arange(5)\n",
    ">>> nc_buf = nc.close() # close returns memoryview\n",
    ">>> print(type(nc_buf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    dimensions(sizes): x(5)\n",
      "    variables(dimensions): int32 v(x)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    ">>> # save nc_buf to disk, read it back in and check.\n",
    ">>> with open('inmemory.nc', 'wb') as f:\n",
    "...     f.write(nc_buf)\n",
    ">>> nc = Dataset('inmemory.nc')\n",
    ">>> print(nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    ">>> print(nc['v'][:])\n",
    ">>> nc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 教程部分结语"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了并行IO示例（位于examples/mpi_example.py），本教程中的所有位于```examples/tutorial.py```中的代码都可用。单元测试位于```test```目录中。\n",
    "\n",
    "**联系人**：Jeffrey Whitaker jeffrey.s.whitaker@noaa.gov\n",
    "\n",
    "**版权**：Jeffrey Whitaker，2008年。\n",
    "\n",
    "**license:** Permission to use, copy, modify, and distribute this software and its documentation for any purpose and without fee is hereby granted, provided that the above copyright notice appear in all copies and that both the copyright notice and this permission notice appear in supporting documentation. THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function部分\n",
    "~~实在是太多了，最好自查，稍微娴熟使用上了再做更多了解（对我本人而言）~~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncl_test1",
   "language": "python",
   "name": "ncl_test1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
